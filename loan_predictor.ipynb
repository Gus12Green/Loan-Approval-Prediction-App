{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53ac7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4269 entries, 0 to 4268\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   loan_id                    4269 non-null   int64 \n",
      " 1    no_of_dependents          4269 non-null   int64 \n",
      " 2    education                 4269 non-null   object\n",
      " 3    self_employed             4269 non-null   object\n",
      " 4    income_annum              4269 non-null   int64 \n",
      " 5    loan_amount               4269 non-null   int64 \n",
      " 6    loan_term                 4269 non-null   int64 \n",
      " 7    cibil_score               4269 non-null   int64 \n",
      " 8    residential_assets_value  4269 non-null   int64 \n",
      " 9    commercial_assets_value   4269 non-null   int64 \n",
      " 10   luxury_assets_value       4269 non-null   int64 \n",
      " 11   bank_asset_value          4269 non-null   int64 \n",
      " 12   loan_status               4269 non-null   object\n",
      "dtypes: int64(10), object(3)\n",
      "memory usage: 433.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    loan_id   no_of_dependents   education      self_employed   income_annum  \\\n",
       " 0        1                  2   Graduate       No                   9600000   \n",
       " 1        2                  0   Not Graduate   Yes                  4100000   \n",
       " 2        3                  3   Graduate       No                   9100000   \n",
       " 3        4                  3   Graduate       No                   8200000   \n",
       " 4        5                  5   Not Graduate   Yes                  9800000   \n",
       " \n",
       "     loan_amount   loan_term   cibil_score   residential_assets_value  \\\n",
       " 0      29900000          12           778                    2400000   \n",
       " 1      12200000           8           417                    2700000   \n",
       " 2      29700000          20           506                    7100000   \n",
       " 3      30700000           8           467                   18200000   \n",
       " 4      24200000          20           382                   12400000   \n",
       " \n",
       "     commercial_assets_value   luxury_assets_value   bank_asset_value  \\\n",
       " 0                  17600000              22700000            8000000   \n",
       " 1                   2200000               8800000            3300000   \n",
       " 2                   4500000              33300000           12800000   \n",
       " 3                   3300000              23300000            7900000   \n",
       " 4                   8200000              29400000            5000000   \n",
       " \n",
       "    loan_status  \n",
       " 0     Approved  \n",
       " 1     Rejected  \n",
       " 2     Rejected  \n",
       " 3     Rejected  \n",
       " 4     Rejected  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import every library needed\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "\n",
    "# Load the CSV file containing the loan dataset\n",
    "ruta_csv = r'C:\\Users\\Usuario\\Documents\\Formaci√≥n\\Code\\Python\\Aplicaciones propias\\Loan Predictor\\loan_approval_dataset.csv'\n",
    "df = pd.read_csv(ruta_csv)\n",
    "\n",
    "# Display general information about the dataset structure and the first few rows\n",
    "df.info(), df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc326aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Accuracy  Precision (1)  Recall (1)  F1-Score (1)\n",
      "Random Forest        0.975410       0.977492    0.955975      0.966614\n",
      "Logistic Regression  0.905152       0.878594    0.864780      0.871632\n",
      "SVM                  0.923888       0.882175    0.918239      0.899846\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the original DataFrame for processing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Remove the unique identifier column (not useful for prediction)\n",
    "df_processed.drop(columns=['loan_id'], inplace=True)\n",
    "\n",
    "# Clean column names by removing leading/trailing spaces\n",
    "df_processed.columns = df_processed.columns.str.strip()\n",
    "\n",
    "# Convert monetary amounts from cents to dollars\n",
    "columns_to_convert = [\n",
    "    'income_annum',\n",
    "    'loan_amount',\n",
    "    'residential_assets_value',\n",
    "    'luxury_assets_value',\n",
    "    'bank_asset_value'\n",
    "]\n",
    "df_processed[columns_to_convert] = df_processed[columns_to_convert] / 100\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "df_processed = pd.get_dummies(df_processed, columns=['education', 'self_employed'], drop_first=True)\n",
    "\n",
    "# Encode the target variable (loan_status) into binary format\n",
    "le = LabelEncoder()\n",
    "df_processed['loan_status'] = le.fit_transform(df_processed['loan_status'])\n",
    "\n",
    "# Split features and target\n",
    "X = df_processed.drop(columns=['loan_status'])\n",
    "y = df_processed['loan_status']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features to normalize the input values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models to train and compare\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = report\n",
    "\n",
    "# Create a summary table with key evaluation metrics\n",
    "summary = pd.DataFrame({\n",
    "    model: {\n",
    "        \"Accuracy\": metrics[\"accuracy\"],\n",
    "        \"Precision (1)\": metrics[\"1\"][\"precision\"],\n",
    "        \"Recall (1)\": metrics[\"1\"][\"recall\"],\n",
    "        \"F1-Score (1)\": metrics[\"1\"][\"f1-score\"]\n",
    "    } for model, metrics in results.items()\n",
    "}).T\n",
    "\n",
    "# Display the summary results\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ba0612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Random Forest': np.float64(0.9777452415812592),\n",
       "  'Logistic Regression': np.float64(0.9191800878477308),\n",
       "  'SVM': np.float64(0.9484626647144948)},\n",
       " {'Random Forest': {'bootstrap': True,\n",
       "   'ccp_alpha': 0.0,\n",
       "   'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_leaf_nodes': None,\n",
       "   'max_samples': None,\n",
       "   'min_impurity_decrease': 0.0,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'min_weight_fraction_leaf': 0.0,\n",
       "   'monotonic_cst': None,\n",
       "   'n_estimators': 200,\n",
       "   'n_jobs': None,\n",
       "   'oob_score': False,\n",
       "   'random_state': 42,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'Logistic Regression': {'C': 0.1,\n",
       "   'class_weight': None,\n",
       "   'dual': False,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_scaling': 1,\n",
       "   'l1_ratio': None,\n",
       "   'max_iter': 1000,\n",
       "   'multi_class': 'deprecated',\n",
       "   'n_jobs': None,\n",
       "   'penalty': 'l2',\n",
       "   'random_state': 42,\n",
       "   'solver': 'lbfgs',\n",
       "   'tol': 0.0001,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'SVM': {'C': 10.0,\n",
       "   'break_ties': False,\n",
       "   'cache_size': 200,\n",
       "   'class_weight': None,\n",
       "   'coef0': 0.0,\n",
       "   'decision_function_shape': 'ovr',\n",
       "   'degree': 3,\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'rbf',\n",
       "   'max_iter': -1,\n",
       "   'probability': False,\n",
       "   'random_state': 42,\n",
       "   'shrinking': True,\n",
       "   'tol': 0.001,\n",
       "   'verbose': False}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the hyperparameter grid for each model\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.1, 1.0, 10.0],\n",
    "        \"penalty\": ['l2'],\n",
    "        \"solver\": ['lbfgs']\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"C\": [0.1, 1.0, 10.0],\n",
    "        \"kernel\": ['linear', 'rbf']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize base models with default parameters\n",
    "base_models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Perform Grid Search Cross Validation for each model\n",
    "best_models = {}\n",
    "best_scores = {}\n",
    "\n",
    "for name in base_models:\n",
    "    grid = GridSearchCV(base_models[name], param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    best_scores[name] = grid.best_score_\n",
    "\n",
    "# Display the best hyperparameters and corresponding cross-validation scores\n",
    "best_scores, {name: model.get_params() for name, model in best_models.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13810135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Accuracy  Precision (1)  Recall (1)  F1-Score (1)\n",
      "Voting Classifier  0.959016       0.949206    0.940252      0.944708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a voting classifier using the best-tuned models from Grid Search\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_models['Random Forest']),\n",
    "        ('lr', best_models['Logistic Regression']),\n",
    "        ('svm', best_models['SVM'])\n",
    "    ],\n",
    "    voting='hard'  # can be set to 'soft' if all models support predict_proba\n",
    ")\n",
    "\n",
    "# Train the ensemble model on the training data\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the ensemble\n",
    "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# Generate classification metrics for the ensemble model\n",
    "report_voting = classification_report(y_test, y_pred_voting, output_dict=True)\n",
    "\n",
    "# Build a summary table of the ensemble model's performance\n",
    "ensemble_summary = pd.DataFrame({\n",
    "    \"Voting Classifier\": {\n",
    "        \"Accuracy\": report_voting[\"accuracy\"],\n",
    "        \"Precision (1)\": report_voting[\"1\"][\"precision\"],\n",
    "        \"Recall (1)\": report_voting[\"1\"][\"recall\"],\n",
    "        \"F1-Score (1)\": report_voting[\"1\"][\"f1-score\"]\n",
    "    }\n",
    "}).T\n",
    "\n",
    "# Display the evaluation results\n",
    "print(ensemble_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "362eee92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the final ensemble model on the entire dataset to maximize available training information\n",
    "voting_clf.fit(scaler.fit_transform(X), y)\n",
    "\n",
    "# Save the trained ensemble model to a file for future use\n",
    "joblib.dump(voting_clf, \"loan_approval_model.pkl\")\n",
    "\n",
    "# Save the fitted scaler to ensure consistent preprocessing during prediction\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7490a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_loan(data, model, scaler):\n",
    "    \"\"\"\n",
    "    Receives a dictionary with loan application data, processes it, and returns the prediction.\n",
    "    \n",
    "    Parameters:\n",
    "        data (dict): Dictionary with input data for a single loan application.\n",
    "        model: Trained machine learning model (e.g., voting ensemble).\n",
    "        scaler: Pre-fitted scaler for numeric feature normalization.\n",
    "    \n",
    "    Returns:\n",
    "        str: Predicted loan status (\"Approved\" or \"Rejected\").\n",
    "    \"\"\"\n",
    "    # Convert the input dictionary to a DataFrame\n",
    "    new_df = pd.DataFrame([data])\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    new_df = pd.get_dummies(new_df)\n",
    "    \n",
    "    # Ensure the input has the same columns as the training data\n",
    "    new_df = new_df.reindex(columns=X.columns, fill_value=0)\n",
    "    \n",
    "    # Scale the numeric features\n",
    "    new_df = scaler.transform(new_df)\n",
    "    \n",
    "    # Generate the prediction\n",
    "    result = model.predict(new_df)\n",
    "    \n",
    "    # Convert numeric prediction back to original label\n",
    "    return le.inverse_transform(result)[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
